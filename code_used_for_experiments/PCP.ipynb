{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !/use/bin/env python\n",
    "# encoding:utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import easy_excel\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import subprocess\n",
    "from sklearn.utils import shuffle\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_fasta_file(path):\n",
    "    '''\n",
    "    used for load fasta data and transformd into numpy.array format\n",
    "    '''\n",
    "    fh=open(m6a_benchmark_dataset)\n",
    "    seq=[]\n",
    "    for line in fh:\n",
    "        if line.startswith('>'):\n",
    "            continue\n",
    "        else:\n",
    "            seq.append(line.replace('\\r\\n',''))\n",
    "    fh.close()\n",
    "    matrix_data=np.array([list(e) for e in seq])\n",
    "    return matrix_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def AthMethPre_extract_one_line(data_line):\n",
    "    '''\n",
    "    extract features from one line, such as one m6A sample\n",
    "    '''\n",
    "    A=[0,0,0,1]\n",
    "    U=[0,0,1,0]\n",
    "    C=[0,1,0,0]\n",
    "    G=[1,0,0,0]\n",
    "    N=[0,0,0,0]\n",
    "    feature_representation={\"A\":A,\"U\":U,\"C\":C,\"G\":G,\"N\":N}\n",
    "    beginning=0\n",
    "    end=len(data_line)-1\n",
    "    alphabet='AUCG'\n",
    "    feature=[]\n",
    "    vector=[\"\".join(e) for e in itertools.permutations(alphabet,2)]\n",
    "    vector.extend(['AA','UU','CC','GG'])\n",
    "    numerate=[(e[0]*10+e[1])/10.0 for e in itertools.permutations([1,2,3,4],2)]\n",
    "    numerate.extend([1.1,2.2,3.3,4.4])\n",
    "    for index,data in enumerate(data_line):\n",
    "        if \"\".join((data,data_line[len(data_line)-1])) in vector and index<=23:\n",
    "            feature.append(numerate[vector.index(\"\".join((data,data_line[len(data_line)-1])))])\n",
    "    return feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A', 'A')\n",
      "('A', 'B')\n",
      "('A', 'C')\n",
      "('A', 'D')\n",
      "('B', 'B')\n",
      "('B', 'C')\n",
      "('B', 'D')\n",
      "('C', 'C')\n",
      "('C', 'D')\n",
      "('D', 'D')\n"
     ]
    }
   ],
   "source": [
    "for e in itertools.combinations_with_replacement(\"ABCD\",2):\n",
    "    print e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def AthMethPre_feature_extraction(matrix_data):\n",
    "    final_feature_matrix=[AthMethPre_extract_one_line(e) for e in matrix_data]\n",
    "    return final_feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "m6a_benchmark_dataset='/home02/chenhuangrong/m6a_data.txt'\n",
    "matrix_data=read_fasta_file(m6a_benchmark_dataset)\n",
    "final_feature_matrix=AthMethPre_feature_extraction(matrix_data)\n",
    "pd.DataFrame(final_feature_matrix).to_csv('/home02/chenhuangrong/Loop_feature.csv',header=None,index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_kmer_list(k, alphabet):\n",
    "    try:\n",
    "        return [\"\".join(e) for e in itertools.product(alphabet, repeat=k)]\n",
    "    except TypeError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0, alphabet must be a string.\")\n",
    "        raise TypeError\n",
    "    except ValueError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0\")\n",
    "        raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall==0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 105.722448383 gamma: 0.00225430205583\n",
      "0.68320610687\n",
      "ACC_all: 0.68320610687\n",
      "c: 15.6221080755 gamma: 0.00586443118104\n",
      "0.69465648855\n",
      "ACC_all: 1.37786259542\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c5a7a769f1f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'kernel'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'rbf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'C'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gamma'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;31m# training model and optimized parameters of C and gamma end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_out_to_excel=[]\n",
    "row0 = [u'特征集', u'样本个数', u'分类器', u'Accuracy', u'Precision', u'Recall', u'SN', u'SP',\n",
    "                u'Gm', u'F_measure', u'F_score', u'MCC', u'ROC曲线面积', u'tp', u'fn', u'fp', u'tn']\n",
    "final_out_to_excel.append(row0) #above was used to generate xlsx format Excel file\n",
    "RNA_code='ACGU' \n",
    "interval=3 # RNA_code and interval used mix used to generate AAA AAC AAG ...\n",
    "division_num=10\n",
    "divided_num=np.float(division_num)# ten fold so the result should divided by ten\n",
    "\n",
    "\n",
    "# seq=[e.replace('U','A') for e in seq]\n",
    "# seq=[e.replace('G','C') for e in seq]\n",
    "seq=pd.read_csv('/home02/chenhuangrong/PCP.csv',header=None,index_col=False)\n",
    "seq=seq.values\n",
    "\n",
    "positive_seq=seq[:len(seq)/2]\n",
    "negative_seq=seq[len(seq)/2:]\n",
    "\n",
    "\n",
    "\n",
    "#define variable to save data which will be saved later --- begining\n",
    "y_pred_prob_all=[]\n",
    "y_pred_all=[]\n",
    "Y_all=[]\n",
    "ACC_all=0\n",
    "precision_all=0\n",
    "recall_all=0\n",
    "SN_all=0\n",
    "SP_all=0\n",
    "GM_all=0\n",
    "TP_all=0\n",
    "TN_all=0\n",
    "FP_all=0\n",
    "FN_all=0\n",
    "F_measure_all=0\n",
    "F1_Score_all=0\n",
    "pos_all=0\n",
    "neg_all=0\n",
    "MCC_all=0\n",
    "#define variable to save data which will be saved later --- end\n",
    "\n",
    "\n",
    "#shuffle the data of positive and negative begining\n",
    "kf = KFold(n_splits=division_num,shuffle=False)  # positive and negative samples will be shuffled \n",
    "for train_index , test_index in kf.split(positive_seq):  \n",
    "    positive_df=pd.DataFrame(positive_seq)\n",
    "    positive_x_train=positive_df.iloc[train_index,:]\n",
    "    positive_y_train=positive_df.iloc[test_index,:]\n",
    "    negative_df=pd.DataFrame(negative_seq)\n",
    "    negative_x_train=negative_df.iloc[train_index,:]\n",
    "    negative_y_train=negative_df.iloc[test_index,:]\n",
    "    positive_negative_x_train=pd.concat([positive_x_train,negative_x_train],axis=0)\n",
    "    positive_negative_y_train=pd.concat([positive_y_train,negative_y_train],axis=0)\n",
    "#shuffle the data of positive and negative end\n",
    "\n",
    "\n",
    "    #generate train and test data begining\n",
    "    X_train = np.array(positive_negative_x_train)\n",
    "    Y_train = list(map(lambda x: 1, xrange(len(X_train) / 2)))\n",
    "    Y2_train = list(map(lambda x: 0, xrange(len(X_train) / 2)))\n",
    "    Y_train.extend(Y2_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    \n",
    "    X_test = np.array(positive_negative_y_train)\n",
    "    Y_test  = list(map(lambda x: 1, xrange(len(X_test) / 2)))\n",
    "    Y2_test  = list(map(lambda x: 0, xrange(len(X_test) / 2)))\n",
    "    Y_test.extend(Y2_test )\n",
    "    Y_test = np.array(Y_test)\n",
    "    #generate train and test data end\n",
    "\n",
    "    \n",
    "    # training model and optimized parameters of C and gamma begining\n",
    "    svc = svm.SVC(probability=True)\n",
    "#     parameters = {'kernel': ['rbf'], 'C':map(lambda x:2**x,np.linspace(-2,5,7)), 'gamma':map(lambda x:2**x,np.linspace(-5,2,7))}\n",
    "    parameters = {'kernel': ['rbf'], 'C':map(lambda x:2**x,np.linspace(-5,15,30)), 'gamma':map(lambda x:2**x,np.linspace(-15,5,30))}\n",
    "    clf = GridSearchCV(svc, parameters, cv=10, n_jobs=12, scoring='accuracy')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    # training model and optimized parameters of C and gamma end\n",
    "    \n",
    "    \n",
    "    #print best C and gamma begining\n",
    "    C=clf.best_params_['C']\n",
    "    gamma=clf.best_params_['gamma']\n",
    "    print 'c:',C,'gamma:',gamma\n",
    "    #print best C and gamma end\n",
    "    \n",
    "    \n",
    "    #getting predict probability and predict label begining\n",
    "    y_pred_prob=clf.predict_proba(X_test)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    #getting predict probability and predict label begining\n",
    "\n",
    "    #the process of generating  usefule data begining\n",
    "    y_pred_prob_all.extend(y_pred_prob)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    Y_all.extend(Y_test)\n",
    "    ACC=metrics.accuracy_score(Y_test,y_pred)\n",
    "    print ACC\n",
    "    precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y_test, y_pred) \n",
    "    F1_Score=metrics.f1_score(Y_test, y_pred)\n",
    "    F_measure=F1_Score\n",
    "    MCC=metrics.matthews_corrcoef(Y_test, y_pred)\n",
    "\n",
    "    pos=TP+FN\n",
    "    neg=FP+TN\n",
    "    ACC_all=ACC_all+ACC\n",
    "    print \"ACC_all:\",ACC_all\n",
    "    precision_all=precision_all+precision\n",
    "    recall_all=recall_all+recall\n",
    "    SN_all=SN_all+SN\n",
    "    SP_all=SP_all+SP\n",
    "    GM_all=GM_all+GM\n",
    "    TP_all=TP_all+TP\n",
    "    TN_all=TN_all+TN\n",
    "    FP_all=FP_all+FP\n",
    "    FN_all=FN_all+FN\n",
    "    F_measure_all=F_measure_all+F_measure\n",
    "    F1_Score_all=F1_Score_all+F1_Score\n",
    "    pos_all=pos_all+pos\n",
    "    neg_all=neg_all+neg\n",
    "    MCC_all=MCC_all+MCC\n",
    "    #the process of generating  usefule data end\n",
    "    \n",
    "#the process of save  data to disk begining   \n",
    "all_y=[np.array(Y_all).astype(int),np.array(y_pred_all).astype(int),np.array(y_pred_prob_all).astype(list)[:,1]]\n",
    "pd.DataFrame(np.matrix(all_y).T).to_csv('/home02/chenhuangrong/PCP_independent_predict.csv',header=None,index=False)\n",
    "fpr, tpr, thresholds = roc_curve(np.array(Y_all).T, list(np.array(y_pred_prob_all).astype(list)[:,1]))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "savedata=[str(X_train.shape[1]),\"正：\"+str(pos_all)+'负：'+str(neg_all),'svm'+\"C:\"+str(C)+\"gamma:\"+str(gamma),ACC_all/divided_num,precision_all/divided_num, recall_all/divided_num,SN_all/divided_num,\n",
    "            SP_all/divided_num, GM_all/divided_num,F_measure_all/divided_num,F1_Score_all/divided_num,MCC_all/divided_num,roc_auc,TP_all,\n",
    "            FN_all,FP_all,TN_all]\n",
    "final_out_to_excel.append(savedata)\n",
    "\n",
    "print savedata\n",
    "\n",
    "pd.DataFrame(final_out_to_excel).to_excel(\"/home02/chenhuangrong/PCP_independent.xlsx\",sheet_name=\"independent_test\",index=False,header=False)\n",
    "#the process of save  data to disk end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
